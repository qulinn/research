# -*- coding: utf-8 -*-
"""unet2-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1amvPsZL65eyjEGL9DWilq4nj14lpe5wo

学習データの一部をテストデータとして、実行
https://github.com/nikhilroxtomar/UNet-Segmentation-in-Keras-TensorFlow/blob/master/unet-segmentation.ipynb
"""


import os
import sys
import random

import numpy as np
import cv2
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow import keras
from DataGen import DataGen

#GPU
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

## Seeding
seed = 2019
random.seed = seed
np.random.seed = seed
tf.seed = seed

"""# hyperparameters"""

image_size = 128
train_path = "/home/izumi/kumo/unet2/dataset/train"
save_path = "/home/izumi/kumo/unet2/code/result3"
epochs = 20
batch_size = 8

## Training Ids
train_ids = next(os.walk(train_path))[1]
print("all train data: ", len(train_ids))

## Validation Data Size
val_data_size = len(train_ids)//10
print("val_data_size: ",val_data_size)

valid_ids = train_ids[:val_data_size]
train_ids = train_ids[val_data_size:]
print("valid data = train data //10")
print("train data: ", len(train_ids), "valid data ",len(valid_ids))


"""# model"""

def down_block(x, filters, kernel_size=(3, 3), padding="same", strides=1):
    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation="relu")(x)
    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation="relu")(c)
    p = keras.layers.MaxPool2D((2, 2), (2, 2))(c)
    return c, p

def up_block(x, skip, filters, kernel_size=(3, 3), padding="same", strides=1):
    us = keras.layers.UpSampling2D((2, 2))(x)
    concat = keras.layers.Concatenate()([us, skip])
    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation="relu")(concat)
    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation="relu")(c)
    return c

def bottleneck(x, filters, kernel_size=(3, 3), padding="same", strides=1):
    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation="relu")(x)
    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation="relu")(c)
    return c

def UNet():
    f = [16, 32, 64, 128, 256]
    inputs = keras.layers.Input((image_size, image_size, 3))

    p0 = inputs
    c1, p1 = down_block(p0, f[0]) #128 -> 64
    c2, p2 = down_block(p1, f[1]) #64 -> 32
    c3, p3 = down_block(p2, f[2]) #32 -> 16
    c4, p4 = down_block(p3, f[3]) #16->8

    bn = bottleneck(p4, f[4])

    u1 = up_block(bn, c4, f[3]) #8 -> 16
    u2 = up_block(u1, c3, f[2]) #16 -> 32
    u3 = up_block(u2, c2, f[1]) #32 -> 64
    u4 = up_block(u3, c1, f[0]) #64 -> 128

    outputs = keras.layers.Conv2D(1, (1, 1), padding="same", activation="sigmoid")(u4)
    model = keras.models.Model(inputs, outputs)
    return model

optimizer=keras.optimizers.Adam(lr=0.0001)

model = UNet()
model.compile(optimizer=optimizer, loss="binary_crossentropy", metrics=["acc"])
model.summary()


"""# training"""

train_gen = DataGen(train_ids, train_path, image_size=image_size, batch_size=batch_size)
valid_gen = DataGen(valid_ids, train_path, image_size=image_size, batch_size=batch_size)

train_steps = len(train_ids)//batch_size
valid_steps = len(valid_ids)//batch_size

training = model.fit(train_gen, validation_data=valid_gen, steps_per_epoch=train_steps, validation_steps=valid_steps, epochs=epochs)



"""学習曲線\
https://www.infiniteloop.co.jp/blog/2018/02/learning-keras-06/
"""

fig = plt.figure()
plt.title("Accuracy")
plt.plot(range(1, epochs+1), training.history['acc'], label="training")
plt.plot(range(1, epochs+1), training.history['val_acc'], label="validation")
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()
fig.savefig(save_path+"/acc.png")

fig = plt.figure()
plt.title("Loss")
plt.plot(range(1, epochs+1), training.history['loss'], label="training")
plt.plot(range(1, epochs+1), training.history['val_loss'], label="validation")
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()
fig.savefig(save_path+"/loss.png")

# testing - validation data"""

## Save the Weights
model.save("model3.h5")
